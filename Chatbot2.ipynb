{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pairuoyefe/ChatBot/blob/main/Chatbot2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k-bJE5K6D3yc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pmSfyOAF0my",
        "outputId": "5c693e02-1860-4af3-c239-8b6fa5cdcb43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day', \"What's up\", 'Yo!', 'Howdy', 'Nice to meet you.'], 'responses': ['Hey', 'Hello, thanks for visiting.', 'Hi there, what can I do for you?', 'Hi there, how can I help?', 'Hello, there.', 'Hello Dear', 'Ooooo Hello, looking for someone or something?', 'Yes, I am here.', 'Listening carefully.', 'Ok, I am with you.']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later.', 'Goodbye', 'Have a great day.', 'See you next time.', 'It was my pleassure.', 'Take care.', 'See ya!', 'Catch you later.', 'Ciao.'], 'responses': ['See you later, thanks for visiting.', 'May the force be with you!', 'See next time.', 'Was my pleassuare to meet you.', 'Hope will cath up sortly.', 'Have a nice day.', 'Bye! Come back again soon.', 'So, till next time.', 'If you need anything just text me anytime. Bye.', 'Well, hope see you soon!']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\", 'Tnx', 'Wow', 'Great!', 'Good!', 'That nice!', 'Amazing!'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure!', 'No problem!', 'Thans does not ', 'Glad to help!', 'No worries!', 'It was the least I could do!', 'If I had a cent for every time I appreciate you, I’d be a millionaire.', \"You can't put thanks in your pocket!\"]}, {'tag': 'tasks', 'patterns': ['What can you do?', 'What are your features?', 'What are you abilities.', 'Can you sing.', 'Can you talk.'], 'responses': ['I can do whatever you asks me to do', 'I can talk and do things for you', \"Right now i'm in developing stage as soon i'm developed, I can do everything\"]}, {'tag': 'alive', 'patterns': ['Are you alive.', 'Do you breathe.', 'Can you run.'], 'responses': [\"I'm in doubt about that\", \"No, i don't think so I need to do all this\"]}, {'tag': 'Menu', 'patterns': ['Which items do you have in your bar?', 'What kinds of items are in you bar?', 'What do you serve?', 'What is in you menu?', 'I need a drink!', 'Do you serve drinks.', 'Menu please!', 'So what is in menu today?', 'Lets check your bar selection!', 'Bar menu for me please!'], 'responses': ['I could serve for your: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'No coffe and no tea, only: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'What about: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer, please choose!', 'Menu: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'Before mans talk choose: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'What about: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'What you prefere: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'Ok our best optins: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'Our bar menu: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.', 'be carreful with your choise: Fuzzy Tauntaun, Bloody Rancor, Jedi Mind Trick, T-16 Skyhopper, Yub Nub, Jet Juice, Hyperdrive, Rancor Beer.']}, {'tag': 'hepl', 'patterns': ['I am looking for help.', 'I need help.', 'Can you help me?', 'I am in trouble need a help.', 'I hope you right person who can help me?', 'Please help me.', 'Now I will need you help with something else.', 'I will need you help.', 'Are you able to help me.', 'PLease help me with something else.'], 'responses': ['Sure, how can in help you.', 'Tell me what do you lookimg for?', 'I will help you, just tell me how.', 'You are at the address.', 'Ok, what is issue?', 'Now you need a help? Ok what you are looking for?', 'Whas is you problem?', 'Ok, you problem is my problem, if your are paying.', 'My help cost a lot.', 'Sure, but nnot for free.']}, {'tag': 'mission', 'patterns': ['I am on mission.', 'I need assistance in my mission.', 'I am looking for partner in mision?', 'Who can assist me with my mission?', 'Do you know any one who can assist me with my mission?'], 'responses': ['Just tell me, you are looking for jedi or sith or bounti hounter?', 'Are you looking for jedi or sith or bounti hounter?', 'Only jedi or sith or bounti hounter can help you.', 'I know only jedi, sith or bounti hounter for it.', 'Ok, some one special from jedi or sith or bounti hounter?', 'I belive jedi or sith or bounti hounter will help you.', 'In this case only jedi or sith or bounti hounter will assist you.', 'Did you deal before with jedi or sith or bounti hounter?', 'Here can help jedi or sith or bounti hounter.', 'Ask for jedi or sith or bounti hounter.']}, {'tag': 'jedi', 'patterns': ['Tell me top 10 jedi?', 'Who is the best jedi in Galaxy?', 'I am looking for the best jedi in galaxi?', 'Which jedi can help me in this mission?', 'I need a help of jedi.'], 'responses': ['Here is top 10 jedi you are looking for. Luke Skywalker, Yoda, Obi-Wan Kenobi, Anakin Skywalker, Qui-Gon Jinn, Mace Windu, Ahsoka Tano, Plo Koon, Aalya Secura, Kit Fisto', 'Luke Skywalker, Yoda, Obi-Wan Kenobi, Anakin Skywalker, Qui-Gon Jinn, Mace Windu, Ahsoka Tano, Plo Koon, Aalya Secura, Kit Fisto.', 'I will advise you to look for Luke Skywalker, Yoda, Obi-Wan Kenobi, Anakin Skywalker, Qui-Gon Jinn, Mace Windu, Ahsoka Tano, Plo Koon, Aalya Secura, Kit Fisto.', 'Only Luke Skywalker, Yoda, Obi-Wan Kenobi, Anakin Skywalker, Qui-Gon Jinn, Mace Windu, Ahsoka Tano, Plo Koon, Aalya Secura, Kit Fisto can help you with it.', 'It so dangerous, the most brave jedi in galaxy Luke Skywalker, Yoda, Obi-Wan Kenobi, Anakin Skywalker, Qui-Gon Jinn, Mace Windu, Ahsoka Tano, Plo Koon, Aalya Secura, Kit Fisto ']}, {'tag': 'sith', 'patterns': ['Tell me top 10 sith?', 'Who is the best sith in Galaxy?', 'I am looking for the best sith in galaxi.', 'Which sith can help me in this mission?', 'I need a help of sith.'], 'responses': ['Here is top 10 sith you are looking for: Darth Vader, Darth Plagueis, Darth Revan, Darth Traya, Darth Sidious, Darth Maul, Ulic Qel-Droma, Asajj Ventress, Kylo Ren, Marka Ragnos.', 'Darth Vader, Darth Plagueis, Darth Revan, Darth Traya, Darth Sidious, Darth Maul, Ulic Qel-Droma, Asajj Ventress, Kylo Ren, Marka Ragnos.', 'I will advise you to look for Darth Vader, Darth Plagueis, Darth Revan, Darth Traya, Darth Sidious, Darth Maul, Ulic Qel-Droma, Asajj Ventress, Kylo Ren, Marka Ragnos.', 'Only Darth Vader, Darth Plagueis, Darth Revan, Darth Traya, Darth Sidious, Darth Maul, Ulic Qel-Droma, Asajj Ventress, Kylo Ren, Marka Ragnos, can help you with it.', 'It so dangerous, the most brave sith in galaxy Darth Vader, Darth Plagueis, Darth Revan, Darth Traya, Darth Sidious, Darth Maul, Ulic Qel-Droma, Asajj Ventress, Kylo Ren, Marka Ragnos.']}, {'tag': 'bounti hounter', 'patterns': ['Tell me top 10 bounti hounter?', 'Who is the bounti hounter sith in Galaxy?', 'I am looking for the best bounti hounter in galaxi.', 'Which bounti hounter can help me in this mission?', 'I need a help of bounti hounter.'], 'responses': ['Here is top 10 bounti hounter you are looking for: Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren.', 'Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren.', 'I will advise you to look for Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren.', 'Only Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren, can help you with it.', 'It so dangerous, the most brave bounti hounter in galaxy Darth Jango Fett, Boba Fett, Cad Bane, Durge, Embo, Dengar, Black Krrsantan, IG-88, Aurra Sing, Sabine Wren.']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Can you be a bit funny', 'Tell me something funny!', 'Do you know a joke?', 'Any joke for me?'], 'responses': ['Which Jedi became a rock star? Bon Jovi-Wan Kenobi.', 'What did Han Solo say to the waiter who recommended the haddock?, Never sell me the cods!', 'What do you need to reroute droids? R2-Detour.', 'Why was the droid angry? Because people kept pushing its buttons.', 'Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.', 'How does Darth Vader like his toast? On the Dark Side.', 'Which program do Jedi use to open PDF files? Adobe-Wan Kenobi', 'What do you call a rebel princess who only shops at Whole Foods? Leia Organic.', 'What’s Yoda’s advice for going to the bathroom? Doo-doo or doo-doo-not-do.', 'I went to a sale at the Maul. Everything was half off.']}, {'tag': 'about me', 'patterns': ['Do you know me?', 'Who am I', 'Tell me about myself', 'Identify me'], 'responses': ['Yes, you are a human', 'You are a dumb person asking a machine about yourself', \"Sorry I can't tell that in public, maybe you are jedi\"]}, {'tag': 'creator', 'patterns': ['Who is your creator?', 'Who created you', 'Who is your father.', 'Who is your daddy.'], 'responses': ['That would be you Mr. ASLAN.', 'I was created by Mr. ASLAN.', 'Mr. ASLAN is my creator.'], 'context_set': ''}, {'tag': 'myself', 'patterns': ['Tell me about Mr. ASLAN?', 'Who is Mr. ASLAN', 'Mr. ASLAN profile', 'Mr. ASLAN details.'], 'responses': ['A very intelligent being who created me', 'My creator, and he is a really intelligent man', 'A wise and intelligent man']}, {'tag': 'stories', 'patterns': ['Tell me a story?', 'Can you tell me a story.'], 'responses': [\"I can't think of anything right now.\", 'It would be too long for me to speak.', 'You would get bored if I do so.']}]}\n"
          ]
        }
      ],
      "source": [
        "# Load JSON\n",
        "with open(\"/content/starwarsintents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Show example\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CbDvzX5IF-Nn"
      },
      "outputs": [],
      "source": [
        "# Collect training data\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        texts.append(pattern)\n",
        "        labels.append(intent[\"tag\"])\n",
        "\n",
        "# Encode labels\n",
        "lbl_encoder = LabelEncoder()\n",
        "labels_encoded = lbl_encoder.fit_transform(labels)\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, padding=\"post\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "bI54osX8Hdph",
        "outputId": "35b1e708-761d-4fb2-8690-168790f74302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,872\u001b[0m (7.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,872</span> (7.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,872\u001b[0m (7.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,872</span> (7.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "output_size = len(lbl_encoder.classes_)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(padded_sequences.shape[1],), activation='relu'))\n",
        "model.add(Dense(output_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nEWoyD8l8APX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n7_ZdYOZ8AoX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tIq08-sH4sM",
        "outputId": "745f709a-6bab-42e6-f35f-cf36bbac7d99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 378ms/step - accuracy: 0.0207 - loss: 26.9041 - val_accuracy: 0.0513 - val_loss: 17.7088\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0227 - loss: 24.5360 - val_accuracy: 0.0769 - val_loss: 15.6625\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0414 - loss: 22.9108 - val_accuracy: 0.0769 - val_loss: 13.8953\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0765 - loss: 19.7063 - val_accuracy: 0.1282 - val_loss: 12.4075\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1031 - loss: 17.0188 - val_accuracy: 0.1282 - val_loss: 11.1152\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1205 - loss: 15.6466 - val_accuracy: 0.1538 - val_loss: 10.0896\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1789 - loss: 14.0854 - val_accuracy: 0.1795 - val_loss: 9.3909\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2807 - loss: 12.7891 - val_accuracy: 0.1795 - val_loss: 8.7488\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2540 - loss: 11.7350 - val_accuracy: 0.2051 - val_loss: 8.1658\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2644 - loss: 11.0639 - val_accuracy: 0.2051 - val_loss: 7.6386\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2222 - loss: 9.9909 - val_accuracy: 0.2051 - val_loss: 7.1191\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2410 - loss: 9.6419 - val_accuracy: 0.2308 - val_loss: 6.6121\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2489 - loss: 8.1668 - val_accuracy: 0.2051 - val_loss: 6.2114\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2053 - loss: 7.6292 - val_accuracy: 0.1795 - val_loss: 5.8770\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2553 - loss: 7.3899 - val_accuracy: 0.2051 - val_loss: 5.4858\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2585 - loss: 6.6574 - val_accuracy: 0.2051 - val_loss: 5.0901\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2742 - loss: 6.3327 - val_accuracy: 0.2308 - val_loss: 4.7513\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2586 - loss: 5.9198 - val_accuracy: 0.2821 - val_loss: 4.4831\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2787 - loss: 5.0565 - val_accuracy: 0.2821 - val_loss: 4.3220\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3241 - loss: 4.4748 - val_accuracy: 0.2821 - val_loss: 4.2027\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3525 - loss: 4.1502 - val_accuracy: 0.2564 - val_loss: 4.0333\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4013 - loss: 3.7307 - val_accuracy: 0.2564 - val_loss: 3.8009\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3371 - loss: 3.5654 - val_accuracy: 0.2821 - val_loss: 3.5271\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3260 - loss: 3.1167 - val_accuracy: 0.3077 - val_loss: 3.2706\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3169 - loss: 2.8551 - val_accuracy: 0.3333 - val_loss: 3.0550\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3318 - loss: 2.5060 - val_accuracy: 0.3590 - val_loss: 2.8744\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3805 - loss: 2.1332 - val_accuracy: 0.4359 - val_loss: 2.7751\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4317 - loss: 1.9133 - val_accuracy: 0.4103 - val_loss: 2.7413\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4420 - loss: 1.8258 - val_accuracy: 0.4359 - val_loss: 2.7172\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4738 - loss: 1.8802 - val_accuracy: 0.4359 - val_loss: 2.6587\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4970 - loss: 1.7476 - val_accuracy: 0.4359 - val_loss: 2.5627\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4898 - loss: 1.6382 - val_accuracy: 0.4615 - val_loss: 2.4393\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5386 - loss: 1.5762 - val_accuracy: 0.4615 - val_loss: 2.3271\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5107 - loss: 1.5251 - val_accuracy: 0.4615 - val_loss: 2.2093\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5251 - loss: 1.3993 - val_accuracy: 0.4872 - val_loss: 2.1180\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5600 - loss: 1.3929 - val_accuracy: 0.4359 - val_loss: 2.0541\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5250 - loss: 1.3082 - val_accuracy: 0.4103 - val_loss: 2.0086\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5185 - loss: 1.3317 - val_accuracy: 0.4615 - val_loss: 1.9668\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4860 - loss: 1.3021 - val_accuracy: 0.4615 - val_loss: 1.9208\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5295 - loss: 1.2398 - val_accuracy: 0.5385 - val_loss: 1.8694\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5963 - loss: 1.2533 - val_accuracy: 0.5385 - val_loss: 1.8135\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5937 - loss: 1.2019 - val_accuracy: 0.5385 - val_loss: 1.7688\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5859 - loss: 1.1643 - val_accuracy: 0.5385 - val_loss: 1.7312\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5756 - loss: 1.2004 - val_accuracy: 0.5128 - val_loss: 1.7185\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5937 - loss: 1.1467 - val_accuracy: 0.5385 - val_loss: 1.6887\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5587 - loss: 1.1633 - val_accuracy: 0.5385 - val_loss: 1.6456\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5677 - loss: 1.1681 - val_accuracy: 0.5641 - val_loss: 1.6273\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6132 - loss: 1.0985 - val_accuracy: 0.5641 - val_loss: 1.6095\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5976 - loss: 1.1466 - val_accuracy: 0.5385 - val_loss: 1.5863\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6027 - loss: 1.1201 - val_accuracy: 0.5385 - val_loss: 1.5568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7812405a5e10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(padded_sequences, labels_encoded, epochs=50, batch_size=64, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)  # 'texts' is your list of patterns\n"
      ],
      "metadata": {
        "id": "mBwomips93Tu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lbl_encoder = LabelEncoder()\n",
        "y = lbl_encoder.fit_transform(labels)\n"
      ],
      "metadata": {
        "id": "SdNhIBgQ96vJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier  # or KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from  sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(texts)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize model (choose one)\n",
        "model = RandomForestClassifier()  # or KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Check accuracy score\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knOhpJLa-HeC",
        "outputId": "26e7cd7b-9861-4830-889e-f0932c36113e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7948717948717948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def chatbot_response(Hi):\n",
        "    # Convert user input to TF-IDF vector (same vectorizer used in training)\n",
        "    X_input = vectorizer.transform([user_input])\n",
        "\n",
        "    # Predict intent label index\n",
        "    pred = model.predict(X_input)\n",
        "\n",
        "    # Convert label index back to tag\n",
        "    tag = lbl_encoder.inverse_transform(pred)[0]\n",
        "\n",
        "    # Find matching responses from your intents data (make sure 'data' is loaded)\n",
        "    for intent in data[\"intents\"]:\n",
        "        if intent[\"tag\"] == tag:\n",
        "            return random.choice(intent[\"responses\"])\n",
        "\n",
        "    return \"Sorry, I don't understand.\"\n"
      ],
      "metadata": {
        "id": "hO1UTu7pAgJw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C_TeO221-HMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the trained model\n",
        "with open(\"rf_chatbot_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "# Save the label encoder\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(lbl_encoder, f)\n"
      ],
      "metadata": {
        "id": "r0BK9WfrA_-9"
      },
      "execution_count": 33,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOVZy5d4nhi5RcJPHThU6cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}